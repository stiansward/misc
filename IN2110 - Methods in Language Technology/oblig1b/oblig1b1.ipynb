{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from in2110.oblig1b import visualize_word_vectors\n",
    "from in2110.corpora import aviskorpus_10_nn\n",
    "import urllib.request, pandas, re, random, numpy as np, scipy, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDFILER = {\"norsk\":\"https://github.com/open-dict-data/ipa-dict/blob/master/data/nb.txt?raw=true\",\n",
    "        \"arabisk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/ar.txt?raw=true\",\n",
    "        \"finsk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/fi.txt?raw=true\",\n",
    "        \"patwa\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/jam.txt?raw=true\",\n",
    "        \"farsi\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/fa.txt?raw=true\",\n",
    "        \"tysk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/de.txt?raw=true\",\n",
    "        \"engelsk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_UK.txt?raw=true\",\n",
    "        \"rumensk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/ro.txt?raw=true\",\n",
    "        \"khmer\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/km.txt?raw=true\",\n",
    "        \"fransk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/fr_FR.txt?raw=true\",\n",
    "        \"japansk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/ja.txt?raw=true\",\n",
    "        \"spansk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/es_ES.txt?raw=true\",\n",
    "        \"svensk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/sv.txt?raw?true\",\n",
    "        \"koreansk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/ko.txt?raw?true\",\n",
    "        \"swahilisk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/sw.txt?raw?true\",\n",
    "        \"vietnamesisk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/vi_C.txt?raw?true\",\n",
    "        \"mandarin\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/zh_hans.txt?raw?true\",\n",
    "        \"malayisk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/ma.txt?raw?true\",\n",
    "        \"kantonesisk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/yue.txt?raw?true\",\n",
    "        \"islandsk\":\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/is.txt?raw=true\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIdentifier:\n",
    "    \"\"\"Logistisk regresjonsmodell som tar IPA transkripsjoner av ord som input, \n",
    "    og predikerer hvilke språkene disse ordene hører til.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialiser modellen\"\"\"\t  \n",
    "        # selve regresjonsmodellen (som brukes all CPU-er på maskinen for trening)\n",
    "        self.model = sklearn.linear_model.LogisticRegression(solver=\"lbfgs\", multi_class='ovr', n_jobs=-1, max_iter=300)\n",
    "\n",
    "        # Hvis den går for treigt kan dere også bruke:\n",
    "        #self.model = sklearn.linear_model.SGDClassifier(loss=\"log\", n_jobs=-1)\n",
    "        \n",
    "        self.symbols = None\n",
    "        self.matrix = None\n",
    "        self.lang_map = None\n",
    "\n",
    "    def train(self, transcriptions, languages):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "        den logistisk regresjonsmodellen. De to rekkene må ha samme lendgen\"\"\"\n",
    "\n",
    "        if self.matrix == None:\n",
    "            self._extract_feats(transcriptions)\n",
    "        self.lang_map = list(ORDFILER.keys())\n",
    "        self.model.fit(self.matrix, [self.lang_map.index(lang) for lang in languages])\n",
    "\n",
    "    def predict(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "        for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "\n",
    "        if self.lang_map == None:\n",
    "            print('Error: Model has to be trained first')\n",
    "            pass\n",
    "        predict_matrix = np.zeros((len(transcriptions), len(self.symbols)))\n",
    "        for i in range(len(transcriptions)):\n",
    "            for char in transcriptions[i]:\n",
    "                if char in self.symbols:\n",
    "                    predict_matrix[i, self.symbols.index(char)] = 1\n",
    "        \n",
    "        return [self.lang_map[n] for n in self.model.predict(predict_matrix)]\n",
    "\n",
    "    def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "        \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "        symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "        counts = {}\n",
    "        for word in transcriptions:\n",
    "            for char in word:\n",
    "                if char in counts.keys():\n",
    "                    counts[char] += 1\n",
    "                else:\n",
    "                    counts[char] = 1\n",
    "        self.symbols = []\n",
    "        for char in counts.keys():\n",
    "            if counts[char] >= min_nb_occurrences:\n",
    "                self.symbols.append(char)\n",
    "        return self.symbols\n",
    "\n",
    "    def _extract_feats(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "        hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "\n",
    "        if self.symbols == None:\n",
    "            self._extract_unique_symbols(transcriptions)\n",
    "        matrix = np.zeros((len(transcriptions), len(self.symbols)))\n",
    "        i = 0\n",
    "        for word in transcriptions:\n",
    "            for char in word:\n",
    "                if char in self.symbols:\n",
    "                    matrix[i, self.symbols.index(char)] = 1\n",
    "            i += 1\n",
    "        self.matrix = scipy.sparse.coo_matrix(matrix)\n",
    "        return self.matrix\n",
    "\n",
    "    def evaluate(self, transcriptions, languages):  \n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "        modellen fungerer ved å beregne:\n",
    "        1) accuracy\n",
    "        2) precision, recall og F1 for hvert språk\n",
    "        3) micro- og macro-averaged F1.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = self.predict(transcriptions)\n",
    "        print('Accuracy score: %.3f' %  sklearn.metrics.accuracy_score(languages, predictions))\n",
    "        \n",
    "        report = sklearn.metrics.classification_report(languages, predictions, output_dict=True)\n",
    "        print('\\t\\tPrecision\\tRecall\\t\\tF1-score')\n",
    "        for key in ORDFILER:\n",
    "            lang = key + '\\t\\t' if len(key) < 8 else key + '\\t'\n",
    "            print(lang + '%.3f' % report[key]['precision'] + '\\t\\t' + '%.3f' % report[key]['recall'] + '\\t\\t' + '%.3f' % report[key]['f1-score'])\n",
    "        \n",
    "        print('Micro-averaged F1: %.3f' % sklearn.metrics.f1_score(languages, predictions, average='micro'))\n",
    "        print('Macro-averaged F1: %.3f' % sklearn.metrics.f1_score(languages, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wordlist(max_nb_words_per_language=20000):\n",
    "    \"\"\"\n",
    "    Laster ned fra Github ordlister med ord og deres phonetiske transkripsjoner i flere språk.\n",
    "    Ordlistene er deretter satt sammen i en pandas DataFrame, og delt i en treningsett og en testsett.\n",
    "    \"\"\"\n",
    "\n",
    "    full_wordlist = []\n",
    "    for lang, wordfile in ORDFILER.items():\n",
    "\n",
    "        #print(\"Nedlasting av ordisten for\", lang, end=\"... \")\n",
    "        data = urllib.request.urlopen(wordfile)\n",
    "\n",
    "        wordlist_for_language = []\n",
    "        for linje in data:\n",
    "            linje = linje.decode(\"utf8\").rstrip(\"\\n\")\n",
    "            word, transcription = linje.split(\"\\t\")\n",
    "\n",
    "            # Noen transkripsjoner har feil tegn for \"primary stress\"\n",
    "            transcription = transcription.replace(\"\\'\", \"ˈ\")\n",
    "\n",
    "            # vi tar den første transkripsjon (hvis det finnes flere) \n",
    "            # og fjerner slashtegnene ved start og slutten\n",
    "            match = re.match(\"/(.+?)/\", transcription)\n",
    "            if not match:\n",
    "                continue\n",
    "            transcription = match.group(1) \n",
    "            wordlist_for_language.append({\"ord\":word, \"IPA\":transcription, \"språk\":lang})\n",
    "        data.close()\n",
    "\n",
    "        # Vi blander sammen ordene, og reduserer mengder hvis listen er for lang\n",
    "        random.shuffle(wordlist_for_language)\n",
    "        wordlist_for_language = wordlist_for_language[:max_nb_words_per_language]\n",
    "\n",
    "        full_wordlist += wordlist_for_language\n",
    "        #print(\"ferdig!\")\n",
    "\n",
    "    # Nå bygger vi en DataFrame med alle ordene\n",
    "    full_wordlist = pandas.DataFrame.from_records(full_wordlist)\n",
    " \n",
    "    # Og vi blander sammen ordene i tilfeldig rekkefølge\n",
    "    full_wordlist = full_wordlist.sample(frac=1)\n",
    "\n",
    "    # Lage et treningssett og en testsett (med 10% av data)\n",
    "    wordlist_train, wordlist_test = sklearn.model_selection.train_test_split(full_wordlist, test_size=0.1)\n",
    "    print(\"Treningsett: %i eksempler, testsett: %i eksempler\"%(len(wordlist_train), len(wordlist_test)))\n",
    "\n",
    "    return wordlist_train, wordlist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treningsett: 309074 eksempler, testsett: 34342 eksempler\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = extract_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.927\n",
      "\t\tPrecision\tRecall\t\tF1-score\n",
      "norsk\t\t0.872\t\t0.812\t\t0.841\n",
      "arabisk\t\t0.963\t\t0.951\t\t0.957\n",
      "finsk\t\t0.988\t\t0.996\t\t0.992\n",
      "patwa\t\t0.937\t\t0.366\t\t0.527\n",
      "farsi\t\t0.939\t\t0.955\t\t0.947\n",
      "tysk\t\t0.958\t\t0.939\t\t0.948\n",
      "engelsk\t\t0.959\t\t0.962\t\t0.961\n",
      "rumensk\t\t0.750\t\t0.807\t\t0.777\n",
      "khmer\t\t0.901\t\t0.668\t\t0.767\n",
      "fransk\t\t0.955\t\t0.912\t\t0.933\n",
      "japansk\t\t0.985\t\t0.936\t\t0.960\n",
      "spansk\t\t0.934\t\t0.917\t\t0.925\n",
      "svensk\t\t0.964\t\t0.956\t\t0.960\n",
      "koreansk\t1.000\t\t0.994\t\t0.997\n",
      "swahilisk\t0.815\t\t0.916\t\t0.863\n",
      "vietnamesisk\t0.974\t\t0.975\t\t0.974\n",
      "mandarin\t0.955\t\t0.978\t\t0.966\n",
      "malayisk\t0.765\t\t0.836\t\t0.799\n",
      "kantonesisk\t0.997\t\t0.974\t\t0.985\n",
      "islandsk\t0.950\t\t0.930\t\t0.940\n",
      "Micro-averaged F1: 0.927\n",
      "Macro-averaged F1: 0.901\n"
     ]
    }
   ],
   "source": [
    "li = LanguageIdentifier()\n",
    "li.train(list(train_data.IPA), list(train_data.språk))\n",
    "li.evaluate(list(test_data.IPA), list(test_data.språk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most weighted symbol in Norwegian: ʋ\n",
      "Average occurrence of ʋ in Norwegian words: 0.173192\n",
      "Average occurrence of ʋ in other words: 0.000000\n",
      "Least weighted symbol in Norwegian: a\n"
     ]
    }
   ],
   "source": [
    "nor_coef = list(li.model.coef_[li.lang_map.index('norsk')])\n",
    "most_weighted = li.symbols[nor_coef.index(max(nor_coef))]\n",
    "least_weighted = li.symbols[nor_coef.index(min(nor_coef))]\n",
    "print('Most weighted symbol in Norwegian:', most_weighted)\n",
    "\n",
    "# Tell antall forekomster av symbolet i norske og ikke-norske ord\n",
    "count_nor = 0\n",
    "nor_words = 0\n",
    "count_not = 0\n",
    "not_words = 0\n",
    "for word, lang in zip(train_data.IPA, train_data.språk):\n",
    "    count = 0\n",
    "    for char in word:\n",
    "        if char == most_weighted:\n",
    "            count += 1\n",
    "    if lang == 'norsk':\n",
    "        nor_words += 1\n",
    "        count_nor += count\n",
    "    else:\n",
    "        not_words += 1\n",
    "        count_not += count\n",
    "print('Average occurrence of %s in Norwegian words: %f' % (most_weighted, count_nor / nor_words))\n",
    "print('Average occurrence of %s in other words: %f' % (most_weighted, count_not / not_words))\n",
    "print('Least weighted symbol in Norwegian: %s' % least_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
